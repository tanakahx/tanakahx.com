
+++
date = "2015-08-03 02:47:22 +0000 UTC"
draft = false
title = "FPGA エクストリーム・コンピューティング"
tags = ["FPGA"]

+++
今日はFPGA エクストリーム・コンピューティング第 7 回の開催日だったのですが、抽選落ちしてからすっかり忘れてて、Twitter の TL で知って慌ててニコ生中継を見ていた次第です。どの発表も非常に興味深かったのですが、特に深層学習の講演がわかりやすくて面白かったです。

<iframe src="https://www.slideshare.net/slideshow/embed_code/key/4duzVExZTkayd7" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/beam2d/chainer-atfpgax7" title="深層学習フレームワークChainerの紹介とFPGAへの期待" target="_blank">深層学習フレームワークChainerの紹介とFPGAへの期待</a> </strong> from <strong><a href="http://www.slideshare.net/beam2d" target="_blank">Seiya Tokui</a></strong> </div><cite class="hatena-citation"><a href="http://www.slideshare.net/beam2d/chainer-atfpgax7">www.slideshare.net</a></cite>

ニューラルネットワークは演算の並列度が高いため FPGA 向きですが、GPU と比較してどうかというポイントが個人的に興味があるところ。誤差逆伝搬法による学習の過程では、各ノードの重みを覚えておく必要があると思いますが、その場合は FPGA の Block RAM (分散 RAM) を使って演算器にデータを素早く供給することができる利点が生かせそうな気がします。ただし、GPU のように潤沢なハードマクロの演算器がないと単純なスループットの点ではなかなか勝つのは難しいかもしれません。


