
+++
date = "2015-09-08 23:30:00 +0000 UTC"
draft = false
title = "誤差逆伝播法を計算中（続き2）"
tags = ["Neural Network"]

+++
誤差逆伝播法で学習ができるようになったのですが、コードが手元にないので載せられません。（涙）というわけで明日に持ち越し。

現状は入力層、中間層、出力層の 3 層からなる最も単純なネットワークで学習してますが、以下の <code>make-network</code> のような関数に各層のノード数をリストで渡すことで、任意のノード数、深さのネットワークを構築できるようにするつもり。

```lisp
(defun make-network (nodes)
  (labels ((make (nodes &amp;key (bias nil))
             (when (second nodes)
               (cons (make-matrix (second nodes)
                                  (if bias 1 (first nodes)))
                     (make (cdr nodes) :bias bias)))))
    (when (&lt; (length nodes) 2)
      (error "Node size is not enough."))
    (list (init-weight (make nodes))
          (init-weight (make nodes :bias t)))))

(defun init-weight (network)
  (loop for n in network
     do (loop for row below (dim n 0)
           do (loop for col below (dim n 1)
                 do (setf (aref n row col)
                          (- (random 2d0) 1d0))))
     finally (return network)))

```


<code>make-network</code> は入力の nodes を元に、各層の重みとバイアスを -1 ~ +1 の範囲の乱数で初期化した行列で返す関数になってます。


